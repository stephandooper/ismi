{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to CAD systems and image processing basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teaching assistants\n",
    "\n",
    "- Kevin Koschmieder: kevin.koschmieder@radboudumc.nl\n",
    "- Hans Pinckaers: hans.pinckaers@radboudumc.nl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students\n",
    "Please fill in this cell with your name and e-mail address. This information will be used to grade your assignment.\n",
    "\n",
    "* Name student #1, email address: ...\n",
    "* Name student #2, email address: ...\n",
    "* Name student #3, email address (optional): ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "* Groups: You should work in **groups of maximum 3 people**.\n",
    "* Deadline for this assignment: \n",
    " * Monday (February 4th) until midnight\n",
    " * 5 points (maximum grade = 100 points) penalization per day after deadline\n",
    "* Send your **fully executed** notebook to: kevin.koschmieder@radboudumc.nl and hans.pinckaers@radboudumc.nl\n",
    "* The file name of the notebook you submit must be ```NameSurname1_NameSurname2_NameSurname3.ipynb```\n",
    "* The grades will be available before February 11th (tentative)\n",
    "\n",
    "This notebooks contains cells with snippets of code that we provide in order to load and visualize data, but also some convenience functions that could be useful to develop your assingment.\n",
    "\n",
    "\n",
    "We also provide templates for functions that have to be implemented, with a given list of input variables and some output variables. **Feel free to modify the input and output variables to adapt them to your favourite implementation.** However, this should at least provide the outputs required to develop the rest of the notebook.\n",
    "\n",
    "\n",
    "Your submission should contain the **fully executed** notebook with **your code** implemented, as well as **your answers** to questions, which will be used to grade your assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this first assignment, we are going to implement and apply some basic image processing techniques, and we will get familiar with some kind of medical imaging data.\n",
    "In particular, we will be working with data from:\n",
    "* mammography (breast, 2D)\n",
    "* histopathology (colon, 2D)\n",
    "* chest CT (lungs, 3D)\n",
    "\n",
    "We will implement the following techniques:\n",
    "1. conversion of raw mammography data into a gray-scale image\n",
    "2. stain normalization in digital pathology with histogram matching\n",
    "3. trachea detection in chest CT with blob detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the basic libraries necessary to develop this assignment. Feel free to include more libraries if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "from IPython import display\n",
    "import time\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import copy\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 12)\n",
    "import scipy.signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data necessary to develop the code in this assignment can be downloaded by executing the next cell (SHIFT+ENTER on the selected cell).\n",
    "All data used in this assignment, as well as in all assignments of this course, are publicly available, and mostly \n",
    "Data are stored in a public folder on SURFDrive.\n",
    "This will download and uncompress data contained in the file ```assignment_1.zip``` to a folder ```/your_notebook_directory/assignment_1```. After the file is unzipped, it is removed.\n",
    "\n",
    "Run the next cell and wait until the progress bar becomes green.\n",
    "On a decent network connection it should take ~1 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753124678f894811ad53c7d32a5561ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Downloading data', max=1, style=ProgressStyâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "link = 'https://surfdrive.surf.nl/files/index.php/s/UEJaScRrPgbySdn/download'\n",
    "file_name = \"assignment_1.zip\"\n",
    "with open(file_name, \"wb\") as f:\n",
    "        response = requests.get(link, stream=True)\n",
    "        total_length = response.headers.get('content-length')\n",
    "        if total_length is None: # no content length header\n",
    "            f.write(response.content)\n",
    "        else:\n",
    "            dl = 0\n",
    "            total_length = int(total_length)\n",
    "            for data in tqdm_notebook(response.iter_content(chunk_size=4096), desc='Downloading data'):\n",
    "                dl += len(data)\n",
    "                f.write(data)\n",
    "with zipfile.ZipFile(file_name,\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"./\")\n",
    "os.remove('./assignment_1.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the downloaded folder contains the following structure:\n",
    "````\n",
    "assignment_1\n",
    "  |-LIDC-IDRI\n",
    "    |-LIDC-IDRI-0001\n",
    "      |-1.3.6.1.4.1.14519.5.2.1.6279.6001.298806137288633453246975630178\n",
    "        |-1.3.6.1.4.1.14519.5.2.1.6279.6001.179049373636438705059720603192\n",
    "          |-000001.dcm\n",
    "          |-...\n",
    "  |-CRC-Prim-HE-05_APPLICATION.tif\n",
    "  |-CRC-Prim-HE-10_APPLICATION.tif\n",
    "  |-processed_mammography.mhd\n",
    "  |-processed_mammography.raw\n",
    "  |-raw_mammography.mhd\n",
    "  |-raw_mammography.raw\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gray-scale transformation of breast tomography (60 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first assignment consists in reconstructing a gray-scale mammography image from the raw data acquired with the mammography machine. As we have seen in the lecture, there are several steps that have to be applied to reconstruct a gray-scale image that can actually be read by radiologists with the aim of detecting tumors, masses, cysts, micro-calcifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Read image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your local data folder, you can find a file containing raw mammography data and the corresponding processed gray-level version. The processed version comes from the vendor and is the result of several filtering and enhancement steps that are proprietary. Our goal is however to do a good job at deriving a gray-level image from raw data.\n",
    "The files are in ITK format, with extension ````.mhd````, and can be opened using the library ````SimpleITK````. You can find documentation on ````SimpleITK```` at this link: http://www.simpleitk.org/SimpleITK/help/documentation.html.\n",
    "In the next cell, we provide the function used to read the raw data and the gray-level images.\n",
    "Furthermore, we indicate which steps have to be implemented.\n",
    "Complete the assignment by implementing the steps indicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw and gray-level data in ITK format\n",
    "raw_img_filename = './assignment_1/raw_mammography.mhd'\n",
    "out_img_filename = './assignment_1/processed_mammography.mhd'\n",
    "\n",
    "# read ITK files using SimpleITK\n",
    "raw_img = sitk.ReadImage(raw_img_filename)\n",
    "out_img = sitk.ReadImage(out_img_filename)\n",
    "\n",
    "# print image information\n",
    "print('image size: {}'.format(raw_img.GetSize()))\n",
    "print('image origin: {}'.format(raw_img.GetOrigin()))\n",
    "print('image spacing: {}'.format(raw_img.GetSpacing()))\n",
    "print('image width: {}'.format(raw_img.GetWidth()))\n",
    "print('image height: {}'.format(raw_img.GetHeight()))\n",
    "print('image depth: {}'.format(raw_img.GetDepth()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">\n",
    "**Question:**\n",
    "What is the pixel size of this image?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Convert ITK image to Numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to easily manipulate data, it is convenient to convert it into a numpy format, which can be transformed using the numpy library, and can easily be visualized using the ````pylab/matplotlib```` library.\n",
    "Please check the documentation in http://insightsoftwareconsortium.github.io/SimpleITK-Notebooks/Python_html/01_Image_Basics.html to find the proper function to transform the SimpleITK image to numpy. Write your code below:\n",
    "* ````out_np````: should contain the numpy array from ````out_img````\n",
    "* ````raw_np````: should contain the numpy array from ````raw_img````\n",
    "\n",
    "Note: If you are not familiar with Numpy, you can check briefly this tutorial: http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE\n",
    "In the rest of this notebook, several cells will contain variables declared as ````None````.\n",
    "This means that you have to replace ````None```` with your own code.\n",
    "We have included checks using the ````assert()```` function to notify that you cannot move to next cells without having replaced ````None```` with a valid expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the ITK image into numpy format\n",
    "# >> YOUR CODE HERE <<<\n",
    "out_np = None\n",
    "raw_np = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(out_np is not None),\"out_np cannot be None\"\n",
    "assert(raw_np is not None),\"raw_np cannot be None\"\n",
    "\n",
    "# visualize the two numpy arrays\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(raw_np, cmap='gray')\n",
    "plt.title('raw data')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(out_np, cmap='gray')\n",
    "plt.title('gray-level data (target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the three main steps necessary to convert raw data into a gray-level image:\n",
    "1. Logaritmic transformation\n",
    "2. Intensity inversion\n",
    "3. Contrast stretching\n",
    "\n",
    "<img src=\"images/raw2gray.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logaritmic transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logarithmic transformation\n",
    "# >> YOUR CODE HERE <<<\n",
    "mammo_log = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(mammo_log is not None),\"mammo_log cannot be None\"\n",
    "\n",
    "# visualize the result\n",
    "plt.imshow(mammo_log, cmap='gray')\n",
    "plt.title('after logaritmic transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intensity inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intensity inversion\n",
    "# >> YOUR CODE HERE <<<\n",
    "mammo_inv = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(mammo_inv is not None),\"mammo_inv cannot be None\"\n",
    "\n",
    "# visualize the result\n",
    "plt.imshow(mammo_inv, cmap='gray')\n",
    "plt.title('after intensity inversion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contrast stretching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to apply the contrast stretching operation, let's first define a general contrast stretching function. The inputs should be at least (1) the input signal, (2) the window range values ```p0``` and ```pk```, as defined in the lecture.\n",
    "**Note**: The end results should not contain intensity values larger than ```pk``` or lower than ```p0```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrast stretching\n",
    "def contrast_stretching(x, p0, pk, q0=0., qk=255.):\n",
    "    # >>> YOUR CODE HERE <<<\n",
    "    x_cs = None\n",
    "    return x_cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply contrast stretching and visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick proper values for p0 and pk\n",
    "p0 = None\n",
    "pk = None\n",
    "\n",
    "assert(p0 is not None),\"p0 cannot be None\"\n",
    "assert(pk is not None),\"pk cannot be None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammo_cs = contrast_stretching(mammo_inv, p0, pk)\n",
    "assert(mammo_cs is not None),\"mammo_cs cannot be None\"\n",
    "\n",
    "# visualize the result\n",
    "plt.imshow(mammo_cs, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that the result at this stage is already much more readable than the raw data you started from. However, the result is still not as good as the one provided by the mammography manufacturer. In order to check for the differences, we will visualize the histogram of the mammography after inversion (before contrast stretching), after contrast stretching and the target one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize and compare histograms\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(mammo_inv.flatten(), 100)\n",
    "plt.title('before contrast stretching')\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(mammo_cs.flatten(), 100)\n",
    "plt.title('after contrast stretching')\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(out_np.flatten(), 100)\n",
    "plt.title('target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">\n",
    "**Question:**\n",
    "How did you define the values of p0 and pk? How much does the result change when this parameters sligthly change? Could you deduce this by having a look at the histogram?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram equalization/matching instead of contrast stretching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The step of contrast stretching could be replaced by a histogram equalization step. In this way, we assume that the target image is known and accessible, from which we will learn some intensity value correspondance function, known as **look-up-table** (LUT). A LUT is a table that has entries that correspond to all possible values in the input image, and each value is mapped to an output value, with the aim of mimicking the intensity distribution of the target image, the vendor mammography in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function that takes as input the histogram to transform and the target histogram and return a LUT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to do histogram matching\n",
    "def get_histogram_matching_lut(h_input, h_template):\n",
    "    ''' h_input: histogram to transfrom, h_template: reference'''\n",
    "    if len(h_input) != len(h_template):\n",
    "        print('histograms length mismatch!')\n",
    "        return False\n",
    "    \n",
    "    # >> YOUR CODE HERE <<\n",
    "    LUT = None\n",
    "    H_input = None # Cumulative distribution of h_input\n",
    "    H_template = None # Cumulative distribution of h_template\n",
    "        \n",
    "    return LUT, H_input, H_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now tha the function ````get_histogram_matching_lut()```` has been implemented, you can execute the next cell, which uses it, and visualize the result of the mammography image converted using histogram matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# rescale images between [0,1]\n",
    "out_np = out_np.astype(float)\n",
    "mammo_inv_norm = (mammo_inv - mammo_inv.flatten().min())/(mammo_inv.flatten().max() - mammo_inv.flatten().min())\n",
    "mammo_out_norm = (out_np - out_np.flatten().min())/(out_np.flatten().max() - out_np.flatten().min())\n",
    "\n",
    "n_bins = None # define the number of bins\n",
    "hist_inv = np.histogram(mammo_inv_norm, bins=np.linspace(0., 1., n_bins+1))\n",
    "hist_out = np.histogram(mammo_out_norm, bins=np.linspace(0., 1., n_bins+1))\n",
    "\n",
    "# compute LUT\n",
    "LUT,H_input,H_template = get_histogram_matching_lut(hist_inv[0], hist_out[0])\n",
    "assert(LUT        is not None),\"LUT cannot be None\"\n",
    "assert(H_input    is not None),\"H_input cannot be None\"\n",
    "assert(H_template is not None),\"H_template cannot be None\"\n",
    "\n",
    "# histograms before matching\n",
    "plt.suptitle('BEFORE HISTOGRAM MATCHING')\n",
    "plt.subplot(1,2,1); plt.hist(mammo_inv_norm.flatten())\n",
    "plt.title('histogram input')\n",
    "plt.subplot(1,2,2); plt.hist(mammo_out_norm.flatten())\n",
    "plt.title('histogram target')\n",
    "plt.show()\n",
    "\n",
    "# plot cumulative histogram\n",
    "plt.suptitle('CUMULATIVE HISTOGRAMS')\n",
    "plt.subplot(1,2,1); plt.plot(H_input)\n",
    "plt.title('cumulative histogram input')\n",
    "plt.subplot(1,2,2); plt.plot(H_template)\n",
    "plt.title('cumulative histogram target')\n",
    "plt.show()    \n",
    "    \n",
    "# apply histogram matching\n",
    "mammo_lut = LUT[(mammo_inv_norm * (n_bins-1)).astype(int)]\n",
    "\n",
    "# visual result\n",
    "plt.suptitle('VISUAL RESULT')\n",
    "plt.subplot(1,2,1); plt.imshow(mammo_lut.squeeze(), cmap='gray')\n",
    "plt.title('converted image')\n",
    "plt.subplot(1,2,2); plt.imshow(out_np, cmap='gray')\n",
    "plt.title('target')\n",
    "plt.show()\n",
    "\n",
    "# histograms after matching\n",
    "plt.suptitle('AFTER HISTOGRAM MATCHING')\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(mammo_lut.flatten())\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(out_np.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question:**\n",
    "How did you pick the number of bins to use to do histogram matching? Does the result depend on the number of bins?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stain normalization with histogram matching (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/stain_examples.png\" alt=\"HE1\" style=\"width:200px\" align=\"right\">\n",
    "\n",
    "In the previous exercise, we implemented a histogram matching function and used it to adapt a given mammography image to a given target image. In that case, the goal was to enhance relevant information in raw mammography data and make it visible as a gray-scale image.\n",
    "\n",
    "The same technique can be applied to the field of digital pathology, but with the aim of solving a different problem, the *variability of stain* across images.\n",
    "In pathology, tissue samples are cut and stained with specific dyes in order to enhance some tissues that are relevant for the diagnosis. The most commonly used staining is called Hematoxylyn and Eosin (H&E), which is routinely applied for diagnostic purposes.\n",
    "The problem with H&E is that there is a large variability of stain across laboratories, and even in the same laboratory, when staining is done in different days of the week. This is because the final result strongly depends on the type and the density of the dyes and on the time the tissue is actually exposed to the dye.\n",
    "\n",
    "The examples on the right are images of colorectal cancer tissue samples, extracted from a publicly available dataset (https://zenodo.org/record/53169#.WJRAC_krIuU), where the appearance, mainly the colour, of the HE-stained images, is different.\n",
    "Histogram matching is a technique that can help solve this problem, since we can think of adapting the distribution of colors per channel (R,G,B) by treating each channel independently.\n",
    "\n",
    "When working with digital pathology images, it is worth noting that the image size is often big. Typical histopathology images are gigapixel images (think of Google maps to get an indea) in the order of 100,000 x 100,000 pixel. However, for the sake of simplicity, in this assignment we will only use tiles of 5000x5000 px."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "HE1 = np.asarray(Image.open('./assignment_1/CRC-Prim-HE-05_APPLICATION.tif'))\n",
    "HE2 = np.asarray(Image.open('./assignment_1/CRC-Prim-HE-10_APPLICATION.tif'))\n",
    "\n",
    "print(HE1.shape)\n",
    "print(HE2.shape)\n",
    "\n",
    "plt.subplot(1,2,1); plt.imshow(HE1); plt.title('HE1')\n",
    "plt.subplot(1,2,2); plt.imshow(HE2); plt.title('HE2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stain normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement your stain normalization function based on histogram matching based on the following definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stain_normalization(input_img, target_img, n_bins=100):\n",
    "    \"\"\" Stain normalization based on histogram matching. \"\"\"\n",
    "    normalized_img = None\n",
    "    # >> YOUR CODE HERE<<\n",
    "    \n",
    "    return normalized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the implemented function to do stain normalization and check the actual result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform HE1 to match HE2\n",
    "HE1_norm = stain_normalization(HE1, HE2);\n",
    "assert(HE1_norm is not None),\"HE1_norm cannot be None\"\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(HE1); plt.title('HE1 before normalization')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(HE1_norm); plt.title('HE1 after normalization')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(HE2); plt.title('target')\n",
    "plt.show()\n",
    "\n",
    "# transform HE2 to match HE1\n",
    "HE2_norm = stain_normalization(HE2, HE1);\n",
    "plt.subplot(1,3,1); plt.imshow(HE2)\n",
    "plt.title('HE2 before normalization')\n",
    "plt.subplot(1,3,2); plt.imshow(HE2_norm)\n",
    "plt.title('HE2 after normalization')\n",
    "plt.subplot(1,3,3); plt.imshow(HE1)\n",
    "plt.title('target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trachea detection in chest CT (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/tracheaAxial.png\"   align=\"right\">\n",
    "\n",
    "The last assignment is about automatic detection of the trachea in slices of a chest CT scan.\n",
    "The detection of the trachea is often used as initialization of airway segmentation algorithms, where the position of the trachea is used as a seed point to grow segmentation methods.\n",
    "For this purpose, we are going to develop a **blob detector** and process all slides of a given scan.\n",
    "The idea is to implement an algorithm that reads an entire CT scan and returns the coordinates (x,y,z) of a point inside the trachea, which can be used as a reliable seed point for future analysis.\n",
    "See the slice besides that shows where to find the trachea. For more images, visit:\n",
    "- http://w-radiology.com/chest_ct.php\n",
    "- http://w-radiology.com/chest_ct-parenchyma.php check it in Coronal view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading DICOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To develop our algorithm, we will use data from the publicly available dataset LIDC-IDRI (https://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI).\n",
    "The database contains 1018 scans, but we will only use the first scan for this assignment, which you can find in the data folder.\n",
    "The format of the chest CT file is DICOM, and for this we will need a dicom library in python (SimpleITK could also be used though).\n",
    "The following code can be used to read all files in a given folder and to open one of those dicom files and convert it into a numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function that reads all files in a directory\n",
    "def get_file_list(path,ext='',queue=''):\n",
    "    if ext != '': return [os.path.join(path,f) for f in os.listdir(path) if f.endswith(''+queue+'.'+ext+'')],  [f for f in os.listdir(path) if f.endswith(''+queue+'.'+ext+'')]    \n",
    "    else: return [os.path.join(path,f) for f in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the first scan from LIDC-IDRI\n",
    "scan_path = './assignment_1/LIDC-IDRI/LIDC-IDRI-0001/1.3.6.1.4.1.14519.5.2.1.6279.6001.298806137288633453246975630178/1.3.6.1.4.1.14519.5.2.1.6279.6001.179049373636438705059720603192'\n",
    "\n",
    "# read all dicom files in the folder\n",
    "dcm_files = sorted(get_file_list(scan_path, 'dcm')[0])\n",
    "n_slices = len(dcm_files)\n",
    "\n",
    "# read one slice and print dicom information\n",
    "slice_idx = 0\n",
    "ct_slice_dicom = dicom.read_file(dcm_files[slice_idx])\n",
    "print(ct_slice_dicom)\n",
    "\n",
    "# convert the slice to a numpy array\n",
    "ct_slice_numpy = ct_slice_dicom.pixel_array\n",
    "dims = ct_slice_numpy.shape\n",
    "\n",
    "# print scan information\n",
    "print('{} dicom files of dimension {} found'.format(n_slices, dims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we store all slices in a scan (3D) matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = np.zeros((dims[0], dims[1], n_slices))\n",
    "for f in range(n_slices):\n",
    "    ds = dicom.read_file(dcm_files[f])\n",
    "    scan[:,:,ds.InstanceNumber-1] = ds.pixel_array\n",
    "print(scan.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed point detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/gaussian.gif\" align=\"right\" width=\"250\">\n",
    "\n",
    "\n",
    "A blob detector is based on a Gaussian function, which has to be applied at a given scale.\n",
    "As a first step, define a function to make Gaussian kernels in 2D, given a value for **sigma in millimiters** given by:\n",
    "\n",
    "\\begin{equation}\n",
    "G(x,y) = \\frac{1}{2\\pi\\sigma^2}\\exp^{-(x^2+y^2)/(2\\sigma^2)}\n",
    "\\end{equation}\n",
    "\n",
    "Do not forget to take into account for the voxel size in x and y direction of the CT scan when designing the filters.\n",
    "This information can be found in the header of the dicom file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_2d(sigma_mm, voxel_size):\n",
    "    kernel = None\n",
    "    x = None # matrix of x coordinates of the filter\n",
    "    y = None # matrix of y coordinates of the filter\n",
    "    return kernel, x, y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laplacian of Gaussian (LoG) <img src=\"images/LoG.png\" width=\"250\" align=\"right\">\n",
    "Now define a function to make the Laplacian of Gaussian defined by:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla^2G(x,y) = \\frac{\\partial^2G(x,y)}{\\partial x^2} + \\frac{\\partial^2G(x,y)}{\\partial y^2}\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_of_gaussian(g):\n",
    "    gxx = None # 2nd derivative w.r.t. x\n",
    "    gyy = None # 2nd derivative w.r.t. y\n",
    "    LoG = None\n",
    "    return LoG, gxx, gyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute LoG\n",
    "g,x,y = gaussian_2d(3.0, [0.7, 0.7])\n",
    "assert(g is not None),\"g cannot be None\"\n",
    "assert(x is not None),\"x cannot be None\"\n",
    "assert(y is not None),\"y cannot be None\"\n",
    "\n",
    "LoG,gxx,gyy = laplacian_of_gaussian(g)\n",
    "assert(LoG is not None),\"LoG cannot be None\"\n",
    "assert(gxx is not None),\"gxx cannot be None\"\n",
    "assert(gyy is not None),\"gyy cannot be None\"\n",
    "\n",
    "#visualize the filters\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(g)\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(gxx)\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(gyy)\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(LoG)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize our Gaussian filter using a surface-like visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter surface visualization\n",
    "g,x,y = gaussian_2d(10.0, [0.7, 0.7])\n",
    "LoG,gxx,gyy = laplacian_of_gaussian(g)\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(x, y, g, antialiased=True, cmap=cm.jet, linewidth=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provide a function that extracts the area that belongs to the thorax for each slice. It is based on some morphology operations that we have not seen yet, so don't worry too much about that, just use it as a black box if you think it can be useful in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the area of the thorax\n",
    "def get_thorax(ct_slice_numpy):\n",
    "    thorax = (ct_slice_numpy > 500)\n",
    "    thorax = scipy.ndimage.morphology.binary_fill_holes(thorax)\n",
    "    label, num_label = scipy.ndimage.label(thorax)\n",
    "    size = np.bincount(label.ravel())\n",
    "    biggest_label = size[1:].argmax() + 1\n",
    "    thorax = (label == biggest_label)\n",
    "    return thorax    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply LoG to all slices in the image. We apply the filter by using the convolution operation. When the filter size becomes big, working in the frequency domain is much faster. For this purpose we can use the fast fourier transform. Think of the size of the filter, whether one filter size is enough or whether multiple sizes have to be used. Tune the scale(s) based on realistic assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement trachea seed point detection\n",
    "#\n",
    "def trachea_seed_point_detection(scan):\n",
    "    # >> YOUR CODE HERE <<\n",
    "    return x,y,z # coordinates of the selected seed point (you can also call it (i,j,k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question:**\n",
    "What are the criteria that you assumed in order to pick the value(s) of sigma?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Question:**\n",
    "Is the seed-point that you found unique, or could you find more than one? In that case, how did you choose the one you used?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here.*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
